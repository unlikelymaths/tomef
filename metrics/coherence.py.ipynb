{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coherence\n",
    "<div style=\"position: absolute; right:0;top:0\"><a href=\"./metrics_index.doc.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">←</font></a>\n",
    "<a href=\"../evaluation.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">↑</font></a></div>\n",
    "\n",
    "`Description`\n",
    "\n",
    "---\n",
    "## Setup and Settings\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b411b686102941368d08ab5b31331239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Topiclist', layout=Layout(width='400px'), options=({'data_name': 'acm', 'token_version':…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .tdalignedlabel {width: 150px;\n",
       "            text-align: left !important; \n",
       "            vertical-align: top !important;\n",
       "            }\n",
       "        .tdalignedvalue {width: 250px;\n",
       "            text-align: left !important; \n",
       "            vertical-align: top !important;\n",
       "            }\n",
       "    </style>\n",
       "<table>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        <b>Data Name</b>\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "         (<font color=\"green\"><b>exists</b></font>)\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        <b>Token Version</b>\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        Cw2v (<font color=\"green\"><b>exists</b></font>)\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        <b>Vocab Version</b>\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        C1 (<font color=\"green\"><b>exists</b></font>)\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        <b>Vector Version</b>\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        B1 (<font color=\"green\"><b>exists</b></font>)\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        <b>Model Name</b>\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        W:  (<font color=\"green\"><b>exists</b></font>), H:  (<font color=\"green\"><b>exists</b></font>), c:  (<font color=\"red\"><b>missing</b></font>)\n",
       "    </td>\n",
       "</tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<widgetbase.StyledHTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d660660dbf048de9bf5ab1f43e97e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __init__ import init_vars\n",
    "init_vars(vars(), ('info', {}))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
    "from gensim.models import CoherenceModel, KeyedVectors\n",
    "from gensim.corpora import WikiCorpus, Dictionary\n",
    "\n",
    "import data\n",
    "import config\n",
    "from base import nbprint\n",
    "from util import ProgressIterator\n",
    "from widgetbase import nbbox\n",
    "from os.path import join, isfile\n",
    "from tokenizer.main import get_tokenizer\n",
    "\n",
    "from metrics.widgets import topiclist_picker\n",
    "\n",
    "if RUN_SCRIPT: topiclist_picker(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## $C_v$ Coherence (Wiki)\n",
    "---\n",
    "\n",
    "`Definition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wiki_dict_filename(wiki_raw_filename, token_version):\n",
    "    return join(config.paths[\"misc\"], wiki_raw_filename + \"{}.txt.bz2\".format(token_version))\n",
    "        \n",
    "def wiki_corpus_filename(wiki_raw_filename, token_version):\n",
    "    return join(config.paths[\"misc\"], wiki_raw_filename + \"{}.bow.mm\".format(token_version))\n",
    "\n",
    "def get_tokenizer_func(token_version):\n",
    "    bcp, id = config.split(token_version)\n",
    "    info = {'token_version': token_version}\n",
    "    if bcp == 'B':\n",
    "        info['token_info'] = config.tokenizer['B'][id]\n",
    "    elif bcp == 'C':\n",
    "        info['embedding_name'] = id\n",
    "        info['embedding_info'] = config.embeddings['C'][id]\n",
    "        info['token_info'] = config.embeddings['C'][id]['token_info']\n",
    "    return get_tokenizer(info)\n",
    "    \n",
    "def make_wikicorpus(wiki_raw_filename, token_version):\n",
    "    nbprint('Scanning Wiki for vocab')\n",
    "    keep_n = 1000000\n",
    "    no_above = 1\n",
    "    no_below = 1\n",
    "    wiki_raw_path = join(config.paths[\"rawdata\"], 'wiki/' + wiki_raw_filename)\n",
    "    tokenizer_func = get_tokenizer_func(token_version).tokenize\n",
    "    \n",
    "    wiki = WikiCorpus(wiki_raw_path, lemmatize=False, tokenizer_func=tokenizer_func)\n",
    "    wiki.dictionary.filter_extremes(no_below=no_below, no_above=no_above, keep_n=keep_n)\n",
    "    wiki.dictionary.save_as_text(wiki_dict_filename(wiki_raw_filename, token_version))\n",
    "    nbprint(' MmCorpus.serialize')\n",
    "    MmCorpus.serialize(wiki_corpus_filename(wiki_raw_filename, token_version), wiki, progress_cnt=10000)\n",
    "\n",
    "def get_dict(wiki_raw_filename, token_version):\n",
    "    nbprint('Loading Dictionary')\n",
    "    wiki_dict_fn = wiki_dict_filename(wiki_raw_filename, token_version)\n",
    "    if not isfile(wiki_dict_fn):\n",
    "        make_wikicorpus(wiki_raw_filename, token_version)\n",
    "    return Dictionary.load_from_text(wiki_dict_fn)\n",
    "\n",
    "def get_corpus(wiki_raw_filename, token_version, dictionary):\n",
    "    nbprint('Loading Corpus')\n",
    "    wiki_raw_path = join(config.paths[\"rawdata\"], 'wiki/' + wiki_raw_filename)\n",
    "    tokenizer_func = get_tokenizer_func(token_version).tokenize\n",
    "    return WikiCorpus(wiki_raw_path, dictionary=dictionary, tokenizer_func=tokenizer_func)\n",
    "\n",
    "def filter_tokens(topiclist, dictionary):\n",
    "    nbprint('Filtering Tokens')\n",
    "    topiclist_reduced = []\n",
    "    removed_tokens = {}\n",
    "    for topic in topiclist:\n",
    "        topic_reduced = []\n",
    "        for entry in topic:\n",
    "            if entry.token in dictionary.token2id:\n",
    "                topic_reduced.append(entry.token)\n",
    "            else:\n",
    "                try:\n",
    "                    removed_tokens[entry.token] += 1\n",
    "                except KeyError:\n",
    "                    removed_tokens[entry.token] = 1\n",
    "        topiclist_reduced.append(topic_reduced)\n",
    "    nbprint(\"Removed {} tokens from {} topics.\".format(len(removed_tokens), len(topiclist)))\n",
    "    return topiclist_reduced\n",
    "\n",
    "def get_coherence_per_topic(topiclist, token_version, coherence_model):\n",
    "    idx = 0\n",
    "    slice_len = 2000\n",
    "    coherences = []\n",
    "    wiki_raw_filename = 'enwiki-20180920-pages-articles1.xml-p10p30302.bz2'\n",
    "    dictionary = get_dict(wiki_raw_filename, token_version)\n",
    "    wiki_corpus = get_corpus(wiki_raw_filename, token_version, dictionary)\n",
    "    nbprint('Computing Coherence')\n",
    "    while idx < len(topiclist):\n",
    "        nbprint('Slice {}-{} of {}'.format(idx, idx+slice_len-1, len(topiclist)))\n",
    "        topiclist_slice = topiclist[idx:idx+slice_len]\n",
    "        topiclist_reduced = filter_tokens(topiclist_slice, dictionary)\n",
    "        cm = CoherenceModel(topics=topiclist_reduced, texts=wiki_corpus.get_texts(), dictionary=dictionary, coherence=coherence_model)\n",
    "        coherences += cm.get_coherence_per_topic()\n",
    "        idx += slice_len\n",
    "    return coherences\n",
    "\n",
    "def cv_wiki(topiclist, token_version):\n",
    "    return get_coherence_per_topic(topiclist, token_version, 'c_v')\n",
    "    \n",
    "def umass_wiki(topiclist, token_version):\n",
    "    return get_coherence_per_topic(topiclist, token_version, 'u_mass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Show all\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Loading Dictionary  \n",
       "\n",
       "Scanning Wiki for vocab  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7846cd6a19434c8e7db717877ad959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if RUN_SCRIPT:\n",
    "    nbbox(mini=True)\n",
    "    topiclist = data.load_topiclist(info)\n",
    "    topiclist = [topic[:10] for topic in topiclist[:2]]\n",
    "    token_version = info['token_version']\n",
    "    if 'second_info' in info:\n",
    "        token_version = info['second_info']['token_version']\n",
    "    u_mass = umass_wiki(topiclist, token_version)\n",
    "    #c_v = cv_wiki(topiclist, token_version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
