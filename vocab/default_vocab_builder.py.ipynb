{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab Builder\n",
    "<div style=\"position: absolute; right:0;top:0\"><a href=\"./vocab.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">←</font></a>\n",
    "<a href=\"../evaluation.py.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">↑</font></a></div>\n",
    "\n",
    "This module provides the `count_tokens()` and the `filter_tokens()` functions.\n",
    "\n",
    "---\n",
    "## Setup and Settings\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a1bed21e18a4f74adac2c83c6de9b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Dataset', layout=Layout(width='400px'), options=(('ACM', 'acm'), ('ATD', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .tdalignedlabel {width: 150px;\n",
       "            text-align: left !important; \n",
       "            vertical-align: top !important;\n",
       "            }\n",
       "        .tdalignedvalue {width: 250px;\n",
       "            text-align: left !important; \n",
       "            vertical-align: top !important;\n",
       "            }\n",
       "    </style>\n",
       "<table>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        <b>Data Name</b>\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        ACM (<font color=\"green\"><b>exists</b></font>)\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        <b>Token Version</b>\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        B0 (<font color=\"green\"><b>exists</b></font>)\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        <b>Vocab</b>\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        <font color=\"green\"><b>exists</b></font>\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        Vocab Version\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        B1\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        Minimum Documents\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        0.0001\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        Minimum Count\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        10\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        Minimum Word Length\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        3\n",
       "    </td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td class=\"tdalignedlabel\">\n",
       "        Maximum Word Length\n",
       "    </td>\n",
       "    <td class=\"tdalignedvalue\">\n",
       "        30\n",
       "    </td>\n",
       "</tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<widgetbase.StyledHTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ae8d63daad4881ac96ddfae76d5f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __init__ import init_vars\n",
    "init_vars(vars(), ('info', {}), ('runvars', {}))\n",
    "\n",
    "import random\n",
    "from operator import attrgetter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('stopwords')\n",
    "            \n",
    "import data\n",
    "import config\n",
    "from base import nbprint\n",
    "from util import ProgressIterator\n",
    "from widgetbase import nbbox\n",
    "\n",
    "from tokenizer.common import split_tokens\n",
    "\n",
    "from vocab.widgets import vocab_picker\n",
    "from vocab.vocab_util import VocabItem,VocabBuilder\n",
    "\n",
    "if RUN_SCRIPT: vocab_picker(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Vocab Builder\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_options = {\n",
    "    'min_docs': False,\n",
    "    'max_docs': False,\n",
    "    'min_count': False,\n",
    "    'min_word_length': False,\n",
    "    'max_word_length': False,\n",
    "    'stopwords': False,\n",
    "    'max_tokens': False,\n",
    "}\n",
    "def get_option(info, option_key):\n",
    "    return info['vocab_info'].get(option_key, default_options[option_key])\n",
    "def to_abs(count, num_docs):\n",
    "    if count <= 0:\n",
    "        return 0\n",
    "    elif count < 1:\n",
    "        return int(count * num_docs)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `def count_tokens()`  \n",
    "Iterates over all tokens and accumulates counts in `rawcounts` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5f6b147ec54e31ae9939305ff6bd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def count_tokens(info, runvars):\n",
    "    rawcounts = {} \n",
    "    num_docs = 0\n",
    "    with data.tokenized_document_reader(info) as documents:   \n",
    "        for document in ProgressIterator(documents, 'Counting Tokens'):\n",
    "            num_docs += 1\n",
    "            tokens = split_tokens(document['tokens'])\n",
    "            for token in tokens:\n",
    "                try:\n",
    "                    rawcounts[token].increase_total()\n",
    "                except KeyError:\n",
    "                    rawcounts[token] = VocabItem(token, total=1)\n",
    "            for token in set(tokens):\n",
    "                rawcounts[token].increase_document() \n",
    "    runvars['rawcounts'] = rawcounts\n",
    "    runvars['num_docs'] = num_docs\n",
    "if RUN_SCRIPT:\n",
    "    nbbox()\n",
    "    count_tokens(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `def sort_counts()`  \n",
    "Turn `rawcounts` dict into list and sort tokens by number of total occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_counts(info, runvars):\n",
    "    runvars['counts'] = sorted(runvars['rawcounts'].values(), \n",
    "        key=attrgetter('total'),\n",
    "        reverse=True)\n",
    "if RUN_SCRIPT:\n",
    "    sort_counts(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the tokens with the highest total counts and some random ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Token | Total | Documents |  \n",
       "|---|---|---|  \n",
       "| the | 277010 | 35583 |  \n",
       "| of | 185336 | 35023 |  \n",
       "| and | 156134 | 34802 |  \n",
       "| to | 132595 | 33689 |  \n",
       "| a | 132406 | 33751 |  \n",
       "| in | 105107 | 32632 |  \n",
       "| we | 64569 | 26439 |  \n",
       "| for | 63666 | 27840 |  \n",
       "| is | 59164 | 25988 |  \n",
       "| that | 56565 | 25983 |  \n",
       "| this | 48611 | 28746 |  \n",
       "| on | 43636 | 23300 |  \n",
       "| with | 37594 | 21311 |  \n",
       "| as | 34664 | 18803 |  \n",
       "| are | 34278 | 19501 |  \n",
       "| Random Tokens: | - | - |  \n",
       "| vetted | 2 | 2 |  \n",
       "| selfadhesive | 1 | 1 |  \n",
       "| paradigmmdashgoal | 1 | 1 |  \n",
       "| selfclassify | 1 | 1 |  \n",
       "| harm | 36 | 32 |  \n",
       "| flushing | 2 | 2 |  \n",
       "| quitcoach | 1 | 1 |  \n",
       "| developdescriptions | 1 | 1 |  \n",
       "| terrorismrelated | 1 | 1 |  \n",
       "| conditioning | 20 | 14 |  \n",
       "| njdhss | 1 | 1 |  \n",
       "| selfadaptable | 1 | 1 |  \n",
       "| bicampus | 2 | 1 |  \n",
       "| metadocuments | 1 | 1 |  \n",
       "| skyband | 1 | 1 |  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1091ad492c458da4f8d52c8351d4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if RUN_SCRIPT:\n",
    "    nbbox()\n",
    "    num_tokens = 15\n",
    "    format_str = '| {} | {} | {} |'\n",
    "    split_line = [VocabItem('Random Tokens:','-','-')]\n",
    "    \n",
    "    nbprint(format_str.format('Token', 'Total', 'Documents'), prefix=False)\n",
    "    nbprint('|---|---|---|', prefix=False)\n",
    "    first_list = runvars['counts'][:num_tokens]\n",
    "    random_list = random.sample(runvars['counts'], num_tokens)\n",
    "    for vocab_item in first_list + split_line + random_list:\n",
    "        nbprint(format_str.format(vocab_item.token, vocab_item.total, vocab_item.document), prefix=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Filter Tokens\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `def filter_min_docs()`\n",
    "Remove tokens occuring in less than `min_docs` documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Removed 54075 tokens occuring in less than 3 documents  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4859a5d4c0874addbefb1339fc6f785d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_min_docs(info, runvars):\n",
    "    min_docs = get_option(info, 'min_docs')\n",
    "    if min_docs:\n",
    "        min_docs = to_abs(min_docs, runvars['num_docs'])\n",
    "        old_length = len(runvars['counts'])\n",
    "        runvars['counts'][:] = [vocab_item for vocab_item in runvars['counts']\n",
    "                                if vocab_item.document >= min_docs]\n",
    "        nbprint('Removed {} tokens occuring in less than {} documents'\n",
    "              .format(old_length - len( runvars['counts']), min_docs))\n",
    "if RUN_SCRIPT:\n",
    "    nbbox(mini = True)\n",
    "    filter_min_docs(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `def filter_max_docs()`\n",
    "Remove tokens occuring in more than `max_docs` documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Removed 20 tokens occuring in more than 14558 documents  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd9ac56440940eb9820d6c0fe6c15a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_max_docs(info, runvars):\n",
    "    max_docs = get_option(info, 'max_docs')\n",
    "    if max_docs:\n",
    "        max_docs = to_abs(max_docs, runvars['num_docs'])\n",
    "        old_length = len(runvars['counts'])\n",
    "        runvars['counts'][:] = [vocab_item for vocab_item in runvars['counts']\n",
    "                                if vocab_item.document <= max_docs]\n",
    "        nbprint('Removed {} tokens occuring in more than {} documents'\n",
    "              .format(old_length - len( runvars['counts']), max_docs))\n",
    "if RUN_SCRIPT:\n",
    "    nbbox(mini = True)\n",
    "    filter_max_docs(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `def filter_min_count()`\n",
    "Remove tokens occuring less than `min_count` times in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Removed 9720 tokens occuring less than 10 times in total.  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83dc580e34814c968896c7055fd70f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_min_count(info, runvars):\n",
    "    min_count = get_option(info, 'min_count')\n",
    "    if min_count:\n",
    "        old_length = len(runvars['counts'])\n",
    "        runvars['counts'][:] = [vocab_item for vocab_item in runvars['counts']\n",
    "                                if vocab_item.total >= min_count]\n",
    "        nbprint('Removed {} tokens occuring less than {} times in total.'\n",
    "              .format(old_length - len( runvars['counts']), min_count))\n",
    "if RUN_SCRIPT:\n",
    "    nbbox(mini = True)\n",
    "    filter_min_count(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `def filter_min_word_length()`\n",
    "Remove tokens of length less than `min_word_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cab928b5969d409a944d6d65268e46d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_min_word_length(info, runvars):\n",
    "    min_word_length = get_option(info, 'min_word_length')\n",
    "    if min_word_length:\n",
    "        old_length = len(runvars['counts'])\n",
    "        runvars['counts'][:] = [vocab_item for vocab_item in runvars['counts']\n",
    "                                if len(vocab_item.token) >= min_word_length]\n",
    "        nbprint('Removed {} tokens with length less than {}'\n",
    "              .format(old_length - len( runvars['counts']), min_word_length))\n",
    "if RUN_SCRIPT:\n",
    "    nbbox(mini = True)\n",
    "    filter_min_word_length(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `def filter_max_word_length()`\n",
    "Remove tokens of length greater than `max_word_length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135af98267e84a899660181fdc0b3269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_max_word_length(info, runvars):\n",
    "    max_word_length = get_option(info, 'max_word_length')\n",
    "    if max_word_length:\n",
    "        old_length = len(runvars['counts'])\n",
    "        runvars['counts'][:] = [vocab_item for vocab_item in runvars['counts']\n",
    "                                if len(vocab_item.token) <= max_word_length]\n",
    "        nbprint('Removed {} tokens with length greater than {}'\n",
    "              .format(old_length - len( runvars['counts']), max_word_length))\n",
    "if RUN_SCRIPT:\n",
    "    nbbox(mini = True)\n",
    "    filter_max_word_length(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `def filter_stopwords()`\n",
    "Remove tokens that are in the nltk stopword corpus `stopwords`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Removed 127 tokens in the english stopword corpus  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad9d7f5ad5840ada5f0c85ae4e51c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_stopwords(info, runvars):\n",
    "    stopwords_corpus_name = get_option(info, 'stopwords')\n",
    "    if stopwords_corpus_name:\n",
    "        stopword_corpus = set(stopwords.words(stopwords_corpus_name))\n",
    "        old_length = len(runvars['counts'])\n",
    "        runvars['counts'][:] = [vocab_item for vocab_item in runvars['counts']\n",
    "                                if vocab_item.token not in stopword_corpus]\n",
    "        nbprint('Removed {} tokens in the {} stopword corpus'\n",
    "              .format(old_length - len( runvars['counts']), stopwords_corpus_name))\n",
    "if RUN_SCRIPT:\n",
    "    nbbox(mini = True)\n",
    "    filter_stopwords(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `def filter_total_size()`\n",
    "Remove tokens until the vocabulary is shorter than `max_tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_total_size(info, runvars):\n",
    "    max_tokens = get_option(info, 'max_tokens')\n",
    "    if max_tokens:\n",
    "        old_length = len(runvars['counts'])\n",
    "        runvars['counts'][:] = runvars['counts'][:max_tokens]\n",
    "        nbprint('Removed {} tokens to limit vocabulary size to {}'\n",
    "              .format(old_length - len( runvars['counts']), max_tokens))\n",
    "if RUN_SCRIPT:\n",
    "    nbbox(mini = True)\n",
    "    filter_stopwords(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `def print_size()`\n",
    "Add an `id` to each token in the final vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "9707 tokens in vocabulary.  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58cac1269ced43468b245b0118012408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', layout=Layout(visibility='hidden'), max=1.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def print_size(info, runvars):\n",
    "    nbprint('{} tokens in vocabulary.'\n",
    "          .format(len(runvars['counts'])))\n",
    "if RUN_SCRIPT:\n",
    "    nbbox(mini = True)\n",
    "    print_size(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build complete vocab functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultVocabBuilder(VocabBuilder):\n",
    "    def build_vocab(self):\n",
    "        runvars = {}\n",
    "        count_tokens(self.info, runvars)\n",
    "        sort_counts(self.info, runvars)\n",
    "        filter_min_docs(self.info, runvars)\n",
    "        filter_max_docs(self.info, runvars)\n",
    "        filter_min_count(self.info, runvars)\n",
    "        filter_min_word_length(self.info, runvars)\n",
    "        filter_max_word_length(self.info, runvars)\n",
    "        filter_stopwords(self.info, runvars)\n",
    "        filter_total_size(self.info, runvars)\n",
    "        print_size(self.info, runvars)\n",
    "        self.counts = runvars['counts']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
