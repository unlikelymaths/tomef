{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocab\n",
    "<div style=\"position: absolute; right:0;top:0\"><a href=\"../evaluation.py.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">â†‘</font></a></div>\n",
    "\n",
    "The vocab module takes the tokenized documents and builds a vocabulary. Certain criteria can be used to filter tokens, such as minimum and maximum length or number of occurrences.\n",
    "\n",
    "---\n",
    "\n",
    "#### [Vocab App](./vocab.app.ipynb)\n",
    "\n",
    "App to run the vocab module for specific settings.\n",
    "\n",
    "#### [Default Vocab Builder](./default_vocab_builder.py.ipynb)\n",
    "\n",
    "Functions for counting and filtering tokens from the vocabulary.\n",
    "\n",
    "---\n",
    "\n",
    "## Info\n",
    "\n",
    "This module first counts all tokens in a corpus using `count_tokens()`.\n",
    "In a second step tokens are filtered from those raw counts using `filter_tokens()` according to the respective vocab version.\n",
    "Finally, all tokens are assigned an id and are saved.\n",
    "\n",
    "## Versions\n",
    "Each vocab version is defined as an entry in `config.vocab['B']` for BoW vocabs and `config.vocab['C']` for cBoW vocabs as follows.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"run\": true,\n",
    "    \"OPTION_1_NAME\": VALUE,\n",
    "    \"OPTION_2_NAME\": VALUE,\n",
    "    \"OPTION_3_NAME\": VALUE,\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "Each option is optional and usually specifies which tokens to exclude from the vocabulary. \n",
    "Numbers strictly between zero and one will be interpreted as relative to the respective count. \n",
    "If set to `false`, which is default, the step will be skipped. \n",
    "These are the options:\n",
    "\n",
    "- `min_docs` (int/float)  \n",
    "  Minimum absolute/relative number of documents that a token must appear in\n",
    "- `max_docs` (int/float)  \n",
    "  Maximum absolute/relative number of documents that a token must appear in\n",
    "- `min_count` (int)  \n",
    "  Minimum absolute number of times a token must be in the corpus in total\n",
    "- `min_word_length` (int)  \n",
    "  Minimum length (in characters) of each token\n",
    "- `max_word_length` (int)  \n",
    "  Maximum length (in characters) of each token\n",
    "- `stopwords` (str)  \n",
    "  Filter stopwrods from the corpus defined by `str`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
