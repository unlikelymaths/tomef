{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer\n",
    "<div style=\"position: absolute; right:0;top:0\"><a href=\"../evaluation.py.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">â†‘</font></a></div>\n",
    "\n",
    "The Tokenizer Module transforms raw text into a list of tokens.\n",
    "\n",
    "---\n",
    "\n",
    "#### [Tokenizer App](./tokenizer.app.ipynb)\n",
    "\n",
    "App to run the tokenizer for specific settings.\n",
    "\n",
    "#### [Tokenize Document App](./tokenize_document.app.ipynb)\n",
    "\n",
    "App to see the tokenization of a specific document.\n",
    "\n",
    "#### [Default Tokenizer](./default_tokenizer.py.ipynb)\n",
    "\n",
    "Default tokenizer pipeline with various settings to tokenize a document string for a BoW representation. \n",
    "\n",
    "#### [PT Tokenizer](./pt_tokenizer.py.ipynb)\n",
    "\n",
    "Wrapper around the Penn Treebank tokenizer.\n",
    "\n",
    "---\n",
    "\n",
    "There are two types of tokenizers:\n",
    "- **(B) BoW**  \n",
    "They follow a default processing pipeline that can be configured via the `tokenizer.versions` config option.\n",
    "They are numbered and have a `B` as prefix. You may have as many configurations as you like.\n",
    "- **(C) cBoW**  \n",
    "For each word embedding type (e.g. `word2vec`) one tokenizer is provided to mimic the tokenization used for the pretrained model.\n",
    "All tokens not in the model are discarded.\n",
    "The tokens are named according to the embedding id (e.g. `w2v`) with `C` as prefix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
