{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize Phrase\n",
    "<div style=\"position: absolute; right:0;top:0\"><a href=\"./vectorizer_index.doc.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">←</font></a>\n",
    "<a href=\"../evaluation.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">↑</font></a></div>\n",
    "\n",
    "`Description`\n",
    "\n",
    "---\n",
    "## Setup and Settings\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __init__ import init_vars\n",
    "init_vars(vars(), ('info', {}), ('runvars', {}), ('num_docs', 400), ('embedding_dim', 200))\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "from base import data, config\n",
    "from interface import nbprint, nbbox, ProgressIterator\n",
    "\n",
    "from embedding.main import get_model\n",
    "\n",
    "from vectorizer.widgets import phrase_vector_picker\n",
    "from vectorizer.plots import plot_matrix\n",
    "\n",
    "if RUN_SCRIPT: phrase_vector_picker(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Phrase Embedding Matrix\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_phrase_mat(info, runvars):\n",
    "    model = get_model(info)\n",
    "    embedding_function = model.embedding_function\n",
    "    batch = []\n",
    "    batchsize = 0\n",
    "    min_batchsize = 4096\n",
    "    current_idx = 0\n",
    "    \n",
    "    # Count documents\n",
    "    num_documents = 0\n",
    "    with data.document_reader(info) as documents:\n",
    "        for document in ProgressIterator(documents, 'Counting Documents'):\n",
    "            num_documents += 1\n",
    "            \n",
    "    # Create a zero matrix\n",
    "    phrase_mat_shape = (model.vector_size, num_documents)\n",
    "    phrase_mat = np.zeros(phrase_mat_shape)\n",
    "    \n",
    "    with data.document_reader(info) as documents:\n",
    "        progress_iterator = ProgressIterator(documents, 'Vectorizing Documents')\n",
    "        for document in progress_iterator:\n",
    "            batch.append(document['text'])\n",
    "            batchsize += 1\n",
    "            \n",
    "            if batchsize >= min_batchsize:\n",
    "                phrase_mat[:,current_idx:current_idx+batchsize] = embedding_function(batch)\n",
    "                current_idx += batchsize\n",
    "                batchsize = 0\n",
    "                batch = []\n",
    "                \n",
    "        if batchsize > 0:\n",
    "            phrase_mat[:,current_idx:current_idx+batchsize] = embedding_function(batch)\n",
    "    runvars['phrase_mat'] = phrase_mat\n",
    "\n",
    "if RUN_SCRIPT:\n",
    "    with nbbox():\n",
    "        make_phrase_mat(info, runvars)\n",
    "        plot_matrix(runvars['phrase_mat'][:embedding_dim,1:num_docs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
