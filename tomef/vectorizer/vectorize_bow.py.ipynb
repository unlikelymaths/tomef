{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize BoW\n",
    "<div style=\"position: absolute; right:0;top:0\"><a href=\"./vectorizer_index.doc.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">←</font></a>\n",
    "<a href=\"../evaluation.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">↑</font></a></div>\n",
    "\n",
    "`Description`\n",
    "\n",
    "---\n",
    "## Setup and Settings\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __init__ import init_vars\n",
    "init_vars(vars(), ('info', {}), ('runvars', {}), ('num_docs', 200), ('num_words', 400))\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from collections import Counter\n",
    "\n",
    "from base import data, config\n",
    "from interface import nbprint, nbbox, ProgressIterator\n",
    "\n",
    "from tokenizer.common import split_tokens\n",
    "\n",
    "from vectorizer.widgets import bow_vector_picker\n",
    "from vectorizer.plots import plot_matrix\n",
    "\n",
    "if RUN_SCRIPT: bow_vector_picker(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Term-Doc Mat\n",
    "---\n",
    "### Count Tokens and build matrix\n",
    "Loads tokenized data and creates a sparse matrix of size number-of-terms by number-of-documents containing absolute counts as entries. Excludes empty documents and stores the ids of the documents in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_term_doc_mat_count(info, runvars):\n",
    "    counts, i, j, mat_ids = [], [], [], []\n",
    "    idx, excluded = 0, 0\n",
    "    vocab = data.load_vocab_dict(info)\n",
    "    \n",
    "    with data.tokenized_document_reader(info) as documents:\n",
    "        for document in ProgressIterator(documents, 'Documents'):\n",
    "            tokens = split_tokens(document['tokens'])\n",
    "            tokencnt = Counter(tokens).most_common()\n",
    "            num_tokens = 0\n",
    "            for token, count in tokencnt:\n",
    "                if token in vocab:\n",
    "                    counts.append(count)\n",
    "                    i.append(vocab[token]['id'])\n",
    "                    j.append(idx)\n",
    "                    num_tokens += count\n",
    "            if num_tokens > 0:\n",
    "                idx += 1\n",
    "                mat_ids.append(document['id'])\n",
    "            else:\n",
    "                excluded += 1\n",
    "    nbprint(\"Documents {}, Excluded {} empty documents\".format(idx, excluded))\n",
    "    term_doc_mat_shape = (len(vocab), idx)\n",
    "    runvars['term_doc_mat_count'] = sparse.coo_matrix((counts, (i, j)), shape=term_doc_mat_shape).tocsc()\n",
    "    runvars['mat_ids'] = mat_ids\n",
    "if RUN_SCRIPT:\n",
    "    with nbbox():\n",
    "        make_term_doc_mat_count(info, runvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term Frequency Matrix\n",
    "\n",
    "Build TF matrix $X$ from count matrix $C$.\n",
    "\n",
    "- `raw`: Counts as integer values\n",
    "$$X_{i\\,j} = C_{i\\,j}$$\n",
    "- `normalized`: Normalize columns to sum to one\n",
    "$$X_{i\\,j} = \\frac{1}{\\sum_k C_{k\\,j}} C_{i\\,j}$$\n",
    "- `boolean`: Entries are zero or one\n",
    "$$X_{i\\,j} = \\begin{cases}\n",
    "1 & C_{i\\,j} > 0 \\\\\n",
    "0 & \\text{else}\n",
    "\\end{cases}$$\n",
    "- `log`: Take the logarithm of the counts (plus one to avoid zero logarithm)\n",
    "$$X_{i\\,j} = \\log(C_{i\\,j} + 1)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_term_doc_mat_tf(info, runvars):\n",
    "    term_doc_mat_count = runvars['term_doc_mat_count']\n",
    "    if info['vector_info']['tf'] == \"raw\":\n",
    "        term_doc_mat_tf = term_doc_mat_count.copy()\n",
    "    elif info['vector_info'][\"tf\"] == \"normalized\":\n",
    "        term_doc_mat_tf = term_doc_mat_count.copy()\n",
    "        column_sum = np.squeeze(np.asarray(\n",
    "            term_doc_mat_count.sum(axis=0)))\n",
    "        normalization = sparse.diags(1/column_sum)\n",
    "        term_doc_mat_tf = term_doc_mat_tf * normalization\n",
    "    elif info['vector_info'][\"tf\"] == \"boolean\":\n",
    "        term_doc_mat_tf = 1*(term_doc_mat_count > 0)\n",
    "    elif info['vector_info'][\"tf\"] == \"log\":\n",
    "        term_doc_mat_tf = term_doc_mat_count.copy()\n",
    "        term_doc_mat_tf.data = np.log(term_doc_mat_tf.data + 1)\n",
    "    runvars['term_doc_mat_tf'] = term_doc_mat_tf\n",
    "if RUN_SCRIPT:\n",
    "    make_term_doc_mat_tf(info, runvars)\n",
    "    plot_matrix(runvars['term_doc_mat_tf'][1:num_words,1:num_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency Matrix\n",
    "\n",
    "Multiply the TF by the IDF matrix $I$ element wise.\n",
    "\n",
    "- `unary`: IDF matrix is all ones\n",
    "$$I_{i\\,j} = 1$$\n",
    "- `idf`: logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_term_doc_mat_idf(info, runvars):\n",
    "    term_doc_mat_tf = runvars['term_doc_mat_tf']\n",
    "    if info['vector_info'][\"idf\"] == \"unary\":\n",
    "        term_doc_mat_tf_idf = term_doc_mat_tf\n",
    "    elif info['vector_info'][\"idf\"] == \"idf\":\n",
    "        word_occurence = np.squeeze(np.asarray(\n",
    "            runvars['term_doc_mat_count'].sum(axis=1)))\n",
    "        total_words = word_occurence.sum()\n",
    "        idf = sparse.diags(np.log(total_words / word_occurence), format='csc')\n",
    "        term_doc_mat_tf_idf = idf * term_doc_mat_tf\n",
    "    runvars['term_doc_mat_tf_idf'] = term_doc_mat_tf_idf.tocsc()\n",
    "if RUN_SCRIPT:\n",
    "    make_term_doc_mat_idf(info, runvars)\n",
    "    plot_matrix(runvars['term_doc_mat_tf_idf'][1:num_words,1:num_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Build complete tokenizer function\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_term_doc_mat_tf_idf(info, runvars):\n",
    "    make_term_doc_mat_tf(info, runvars)\n",
    "    make_term_doc_mat_idf(info, runvars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
