{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding\n",
    "<div style=\"position: absolute; right:0;top:0\"><a href=\"../evaluation.py.ipynb\" style=\"text-decoration: none\"> <font size=\"5\">â†‘</font></a></div>\n",
    "\n",
    "The Embedding Module is responsible for loading word and phrase embeddings and providing them to the other modules.\n",
    "\n",
    "---\n",
    "\n",
    "## General\n",
    "\n",
    "Each embedding is specified as an entry in the configuration. Word embedding models are listed in `config.embeddings['C']` as \n",
    "\n",
    "```json\n",
    "\"identifier\": {\n",
    "    \"name\": STRING,\n",
    "    \"run\": BOOLEAN,\n",
    "    \"mod\": STRING,\n",
    "    \"cls\": STRING,\n",
    "    \"token_info\": {\n",
    "        \"mod\": STRING,\n",
    "        \"cls\": STRING\n",
    "    },\n",
    "    OPTIONAL_PARAMETERS\n",
    "    }\n",
    "```\n",
    "\n",
    "and phrase embedding models in `config.embeddings['P']` as\n",
    "\n",
    "```json\n",
    "\"identifier\": {\n",
    "    \"name\": STRING,\n",
    "    \"run\": BOOLEAN,\n",
    "    \"mod\": STRING,\n",
    "    \"cls\": STRING,\n",
    "    OPTIONAL_PARAMETERS\n",
    "    }\n",
    "```\n",
    "\n",
    "with the following entries:\n",
    "\n",
    "- `identifier` specifies the embedding. Must be unique within each class (`C` and`P`).\n",
    "- `name` is a full name used for printing output\n",
    "- `run` defines whether the evaluation script will run anything related to this embedding\n",
    "- `mod` module path of the embedding model\n",
    "- `cls` class name of the embedding model\n",
    "- `token_info` the tokenizer used for the tokenization. For parameters see [tokenizer](../tokenizer/tokenizer.ipynb).\n",
    "- `OPTIONAL_PARAMETERS` will usually be a filename or a URL of the trained model\n",
    "\n",
    "---\n",
    "\n",
    "## Word Embeddings (C)\n",
    "\n",
    "During evaluation additional files will be created, e.g. `<id>.vocab.txt` containing the vocabulary of the embeddings for faster lookups.\n",
    "\n",
    "### [Word2vec](./word2vec.py)\n",
    "**Mod.Cls**  \n",
    "`word2vec.Word2vecModel`  \n",
    "**Parameters**  \n",
    "`filename`  \n",
    "**Install**  \n",
    "Download a pretrained model from \n",
    "https://code.google.com/archive/p/word2vec/\n",
    "(see \"The archive is available here: GoogleNews-vectors-negative300.bin.gz\")\n",
    "and extract it to `data/embedding`.\n",
    "Alternatively you may train a model yourself. Set the `filename` entry in your config to this file.\n",
    "\n",
    "### GloVe (Currently not implemented)\n",
    "Download one or multiple pretrained models from\n",
    "https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "\n",
    "### fastText (Currently not implemented)\n",
    "https://fasttext.cc/docs/en/english-vectors.html \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Phrase Embeddings (P)\n",
    "\n",
    "### [Universal Sentence Encoder](./use.py)\n",
    "**Mod.Cls**  \n",
    "`use.USEModel`  \n",
    "**Parameters**  \n",
    "`module_url`  \n",
    "**Install**\n",
    "Will be automatically downloaded as a *TensorFlow Hub* module from the `module_url` specified in the config. See\n",
    "https://tfhub.dev/google/universal-sentence-encoder/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Markdown",
   "language": "markdown",
   "name": "markdown"
  },
  "language_info": {
   "codemirror_mode": "markdown",
   "file_extension": ".md",
   "mimetype": "text/markdown",
   "name": "Markdown",
   "pygments_lexer": "markdown"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
